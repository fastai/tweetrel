{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp core\n",
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Creating tweetrel\n",
    "> and an overview of its API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create this library, we will start out by following the initial steps of the [nbdev tutorial](https://nbdev.fast.ai/tutorial.html) to create a basic project structure. We also need to install [ghapi](https://ghapi.fast.ai/), by following the instructions on that link.\n",
    "\n",
    "Once we have a repo cloned, based on the `nbdev_template` template, we run in our terminal:\n",
    "\n",
    "```bash\n",
    "gh-create-workflow tweet release --contexts secrets\n",
    "```\n",
    "\n",
    "Note that we add `--contexts secrets` because we'll need access to the [secrets context](https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets#using-encrypted-secrets-in-a-workflow), which we'll be using to store our Twitter API keys.\n",
    "\n",
    "The basic workflow skeleton that this creates is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1) [Path('.github/workflows/tweet-release.yml')],\n",
       " (#1) [Path('.github/scripts/build-tweet-release.py')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_path  = Path('.github/workflows')\n",
    "scr_path = Path('.github/scripts')\n",
    "wf_path.ls(),scr_path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Twitter authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to send tweets, we'll send to use the Twitter API -- we'll use the `tweepy` library for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Twitter part of this tutorial isn't the main thing we want to explain, but the thing to note carefully here is how to access *secrets* in your workflow.\n",
    "\n",
    "The Twitter API requires authentication, so we'll store our details in a GitHub secret. We'll just use one secret, we our keys stored space delimited. We generally use an [organization secret](https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-an-organization), so that we can update secrets in one place as needed.\n",
    "\n",
    "Contexts are passed to ghapi as json-encoded environment variables. Each variable name starts with `CONTEXT_` -- so for instance the `secrets` context is `CONTEXT_SECRETS`. In order to simulate this when testing, ensure that you have set an appropriate environment variable before importing `ghapi`. We've put our JSON encoded secrets for testing into a `.secrets` file (which we added to `.gitignore` so it wouldn't be pushed to our repo), so we'll use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CONTEXT_SECRETS'] = Path('.secrets').read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import `ghapi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "from ghapi import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now check the `context_secrets` variable, you should find your secrets available as an `AttrDict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'TWITTER' in context_secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a function to unpack our keys, tokens, and secrets for Twitter auth, and login to the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def twitter_api():\n",
    "    consumer_key,consumer_secret,access_token,access_token_secret = context_secrets.TWITTER.split()\n",
    "    auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "    auth.set_access_token(access_token,access_token_secret)\n",
    "    return tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test our login by creating and deleting a tweet:\n",
    "\n",
    "```python\n",
    "import time\n",
    "twapi = twitter_api()\n",
    "stat = twapi.update_status(\"Please ignore - testing API\")\n",
    "time.sleep(1)\n",
    "twapi.destroy_status(stat.id)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responding to the `release` event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a sample `release` event payload as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['action', 'release', 'repository', 'sender'], 'published')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = example_payload(Event.release)\n",
    "list(example), example.action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `release` section has the following keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'url, assets_url, upload_url, html_url, id, node_id, tag_name, target_commitish, name, draft, author, prerelease, created_at, published_at, assets, tarball_url, zipball_url, body'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(example.release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a function that formats a tweet based on this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def tweet_text(payload):\n",
    "    rel = payload.release\n",
    "    owner,repo = re.findall(r'https://api.github.com/repos/([^/]+)/([^/]+)/', rel.url)[0]\n",
    "    tweet_tmpl = \"New #{repo} release: v{tag_name}. {html_url}\\n\\n{body}\"\n",
    "    res = tweet_tmpl.format(repo=repo, tag_name=rel.tag_name, html_url=rel.html_url, body=rel.body)\n",
    "    if len(res)<=280: return res\n",
    "    return res[:279] + \"â€¦\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New #Hello-World release: v0.0.1. https://github.com/Codertocat/Hello-World/releases/tag/0.0.1\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tweet_text(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample release payload from GitHub happens to have an empty `body`, but other than that, this looks good.\n",
    "\n",
    "That's all we need to create our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def send_tweet():\n",
    "    payload = context_github.event\n",
    "    if 'workflow' in payload: payload = example_payload(Event.release)\n",
    "    if payload.action == 'published': return twitter_api().update_status(tweet_text(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pop this into our python script, along with `send_tweet()`. Since we're using nbdev, we can enter the following in our terminal to do all that:\n",
    "\n",
    "```bash\n",
    "nbdev_build_lib\n",
    "cp tweetrel/core.py .github/scripts/build-tweet-release.py\n",
    "echo -e \"\\nsend_tweet()\" >>  .github/scripts/build-tweet-release.py\n",
    "```\n",
    "\n",
    "After we push to GitHub, we can test it out in the same way we showed in the [GitHub Actions tutorial](https://ghapi.fast.ai/tutorial_actions.html), first by logging in and getting a reference to our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = GhApi(owner='fastai', repo='tweetrel', token=github_token())\n",
    "wf = api.actions.get_workflow('tweet-release.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then running it:\n",
    "\n",
    "```python\n",
    "api.actions.create_workflow_dispatch(wf.id, ref='master')\n",
    "```\n",
    "\n",
    "After you run this, you should find the workflow appears in your \"Actions\" tab on GitHub, and a tweet will appear in your twitter timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some little improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue is that currently you'll see three workflows being triggered on the Actions tab in GitHub. That's because the \"created\" and \"released\" types are resulting in a trigger, as well as \"published\". Our function is checking which is being used, and only tweeting for \"published\", but the runs are still being recorded. This isn't necessarily a big problem, but if you'd like things to be cleaner, you can edit the `tweet-release.yml` file to add the following line after the `release:` line:\n",
    "\n",
    "```bash\n",
    "types: [published]\n",
    "```\n",
    "\n",
    "It's also possible to do a more complete end-to-end test by actually making a release, checking that a new run is created, and checking the result of that run:\n",
    "\n",
    "```python\n",
    "n_runs = api.actions.list_workflow_runs(wf.id).total_count\n",
    "try:\n",
    "    rel = api.create_release('test', body='body')\n",
    "    time.sleep(30)\n",
    "    runs = api.actions.list_workflow_runs(wf.id)\n",
    "    test(runs.total_count, n_runs, gt)\n",
    "    test_eq(runs.workflow_runs[0].conclusion, 'success')\n",
    "finally: api.delete_release(rel)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributing your new Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above steps are all that's needed to create a Python-based workflow for use in a single project. To make it accessible for any project (including other people's projects), we need to distribute it. The easiest way to do that is with `pip`. `pip` can install modules directly from GitHub, or from the PyPi repository.\n",
    "\n",
    "Our first step is to add a command that makes it easy to install the `tweetrel` workflow into a project. We can use `fastcore.script.call_parse` to create a function that can be run from the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "from fastcore.script import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function, we'll use `fill_workflow_templates` instead of `gh-create-workflow` because it allows us to customize each part of the YAML workflow file exactly as we need it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "@call_parse\n",
    "def install():\n",
    "    fill_workflow_templates(\n",
    "        name='tweet', event=\"release:\\n  types: [published]\",\n",
    "        run=f'pip install -Uq git+https://github.com/fastai/tweetrel.git',\n",
    "        context=env_contexts('secrets'),\n",
    "        script=\"import tweetrel\\ntweetrel.send_tweet()\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
